# ğŸ§­ LLM Travel Assistant â€“ End-to-End MLOps Deployment

## ğŸš€ Overview
The **LLM Travel Assistant** is an intelligent conversational travel guide powered by **Groq LLMs**, capable of generating personalized trip itineraries, travel tips, and destination insights.  
This project demonstrates a complete **MLOps pipeline**, from model inference to deployment and observability.

## ğŸ§  Features
- **Conversational LLM Integration:** Leveraged **Groq LLM** for ultra-fast natural language inference.
- **Streamlit Frontend:** Interactive UI for dynamic travel assistance and trip planning.
- **Cloud Deployment:** Hosted on **Google Cloud VM** for scalable infrastructure.
- **Containerization & Orchestration:** Built using **Docker**, **Minikube**, and **kubectl** for Kubernetes-based orchestration.
- **Monitoring & Logging:** Integrated **ELK Stack** (**Elasticsearch**, **Logstash**, **Filebeat**, **Kibana**) for centralized log management and visualization.
- **CI/CD Ready:** Modular design supports continuous integration and deployment pipelines.

## âš™ï¸ Tech Stack
`Groq LLM` Â· `Streamlit` Â· `Python` Â· `Docker` Â· `Minikube` Â· `kubectl` Â· `GCP VM` Â· `Elasticsearch` Â· `Filebeat` Â· `Logstash` Â· `Kibana`

## ğŸ§© Architecture
```
User â†’ Streamlit UI â†’ Groq API â†’ Dockerized Service â†’ GCP VM
                                    â†“
                           ELK Stack for Logging
```
- **Filebeat**: Collects logs from application containers.
- **Logstash**: Processes and sends data to Elasticsearch.
- **Elasticsearch**: Stores and indexes logs.
- **Kibana**: Visualizes system metrics and logs.

## â˜ï¸ Deployment
- Deployed on **Google Cloud VM**
- Dockerized microservices for scalability
- Kubernetes used for container orchestration
